# Obtaining Latent Representations of natural images using Reverse GANs
## Abstract
I have explored the possibility of extracting latent vectors from natural images. A deep convolutional Generative Adversarial Network (DCGAN) discriminator was adapted and implemented as a latent encoder for images, trained to predict the latent vectors of images generated by StyleGAN. Two of these models were trained, one for face images and one for ImageNet-like images. The face image model is able to accurately capture defining visual properties and reconstruct near identical images, while the ImageNet-like image model produces latent vectors that correspond to the original input images in their semantics but not always in their structure.

## Repository layout
In this repository are all the files used to create and train the models, as well as the saved model weights of already trained models. \
The folder _Training_ contains the notebooks and .py files that were used to train the networks, using both StyleGAN3 and StyleGANXL. \
The folder _Analysis_ contains the notebooks that contain code to use pre-trained networks to generate reconstructions of input images. \
The folder _Models_ contains these pre-trained networks (trained on StyleGAN3 and on StyleGANXL) for various different training lengths (iterations). \
Finally, the folder _Results_ contains 10 sample input images along with reconstructions made by models trained for different iterations.
