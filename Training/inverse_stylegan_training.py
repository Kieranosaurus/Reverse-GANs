# -*- coding: utf-8 -*-
"""Inverse_StyleGAN_Training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dSBSWUL5ke2i9D28d9cujVyorE_4upkL
"""

import sys
sys.path.append('./stylegan3')

import numpy as np
import torch
import torch.nn as nn
import tensorflow as tf
import pickle
import os

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import pandas as pd
import PIL
from PIL import Image
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import torch.optim as optim

import torch_utils
import legacy
import dnnlib

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print('Using device:', device, file=sys.stderr)

# Load in the trained Stylegan3 model
network_pkl = "https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhq-1024x1024.pkl"
with dnnlib.util.open_url(network_pkl) as f:
        G = legacy.load_network_pkl(f)['G_ema']
        G = G.eval().requires_grad_(False).to(device)
c = None

def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

def get_latents(amount, seed, shape = 512):
    latents = torch.from_numpy(np.random.RandomState(seed).randn(amount, shape)).cuda()
    w = torch.empty(amount, 16, shape)
    for i in range(latents.shape[0]):
        w[i] = G.mapping(latents[i][None], c)
    return latents, w

def face_from_latent(net, latents, img_size, show_face = False, use_w=False, outdir = None):
    outputs = torch.empty((len(latents), 3, img_size, img_size))
    transform=transforms.Compose([transforms.Resize(img_size),transforms.CenterCrop(img_size),transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])
    for i, latent in enumerate(latents):
        if use_w:
            face = net.synthesis(latent[None], noise_mode = "none")
        else:
            face = net(latent[None], c)
        face = np.clip(np.rint((face.cpu() + 1.0) / 2.0 * 255.0), 0.0, 255.0).numpy().astype(np.uint8)
        face = face.transpose((0, 2, 3, 1))
        img = Image.fromarray(face[0], 'RGB')
        img = img.resize((img_size,img_size), resample = PIL.Image.LANCZOS)
        if show_face:
            plt.axis('off')
            plt.title("Face "+str(i))
            plt.imshow(img)
            plt.show()
        if not outdir is None:
          img.save(outdir + "Image %d.png" % i)
        img = transform(img)
        outputs[i] = img
    return outputs

def train(netD, netG, num_iters, batch_size, img_size, seed, criterion, optimizer):
    losses = []
    for i in range(num_iters):
        z, w = get_latents(batch_size, np.random.seed(seed))
        z = z.to(torch.float32).to(device)
        w = w.to(device) # naar float32?
        x = face_from_latent(netG, w, img_size, use_w = True).to(device)

        netD.zero_grad()

        output = netD(x).squeeze()

        errD = criterion(output, w[:,0])
        errD.backward()
        optimizer.step()
        
        if i % 5 == 0:
          print('[%d/%d]\tLoss_D: %.4f' % (i+1, num_iters, errD.item()))

        losses.append(errD.item())

    return losses

class Discriminator(nn.Module):
    def __init__(self, channels = 3, feature_maps = 64):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(channels, feature_maps, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(feature_maps, feature_maps * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(feature_maps * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(feature_maps * 2, feature_maps * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(feature_maps * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(feature_maps * 4, feature_maps * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(feature_maps * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(feature_maps * 8, 512, 4, 1, 0, bias=False),
        )

    def forward(self, input):
        return self.main(input)

# Set number of gpu's and device
img_size = 64

# seed = 42
# outdir = 'output/'
# os.makedirs(outdir, exist_ok=True)
# batch_sz = 5
#
# z, w = get_latents(batch_sz, seed)
# z = z.to(torch.float32).to(device)
# w = w.to(device) # naar float32?
# print(w.shape)
#
# outputs = face_from_latent(G, w, 1024, use_w = True, outdir=outdir).to(device)

netD_Adam_W = Discriminator().to(device)
# netD_Adam_W.apply(weights_init)
optimizerD_Adam_W = optim.Adam(netD_Adam_W.parameters(), lr=0.0002)
criterion = nn.MSELoss()

path = 'intermediate_results/netD_stylegan3-1024_w_30000.pt'
checkpoint = torch.load(path)
netD_Adam_W.load_state_dict(checkpoint['model_state_dict'])
optimizerD_Adam_W.load_state_dict(checkpoint['optimizer_state_dict'])
iter = checkpoint['iter']
loss = checkpoint['loss']

print(netD_Adam_W)
# print(iter)

# Number of training epochs
num_iters = 10000

# Set batch size, for number of generated samples per epoch
batch_size = 32

# Set random seed
seed = 42

losses_adam_w = train(netD_Adam_W, G, num_iters, batch_size, img_size, seed, criterion, optimizerD_Adam_W)

# plt.figure(figsize=(10,5))
# plt.title("Discriminator Loss During Training")
# plt.plot(losses_adam_w,label="Loss")
# plt.xlabel("Number of epochs")
# plt.ylabel("Loss")
# plt.legend()
# plt.show()

iter = 40000
path = 'intermediate_results/netD_stylegan3-1024_w_40000.pt'
loss = losses_adam_w[-1]

torch.save({
    'iter': iter,
    'model_state_dict': netD_Adam_W.state_dict(),
    'optimizer_state_dict': optimizerD_Adam_W.state_dict(),
    'loss': loss,
}, path)
